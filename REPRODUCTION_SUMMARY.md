# TracLLM 论文复现总结报告 (DeepSeek-V3)

本报告总结了在本地环境适配代码并接入 DeepSeek-V3 API 后，对 TracLLM 框架在 Prompt Injection（指令注入）和 Knowledge Corruption（知识投毒）两类任务上的复现结果与评估。

## 1. 复现环境与适配

由于本地环境（Windows + 消费级显卡/CPU）与论文原环境（Linux + A100 集群）存在差异，我们进行了深度的代码适配：

*   **模型轻量化**：实现了 `GPT` 类对 DeepSeek API 的支持，替代了原论文中庞大的 Llama-3-8B 本地模型，大幅降低了硬件门槛。
*   **依赖与平台修复**：解决了 `flash-attn` 等库在 Windows 下的兼容性问题，修复了 `signal` 模块在 Windows 下缺失导致的运行错误。
*   **数据与网络**：配置了 Hugging Face 镜像源，手动下载并挂载了 `LongBench` 等数据集，解决了网络连接重置问题。
*   **评估脚本重构**：编写了专用的 `run_deepseek_reproduce.py` 启动脚本和 `analyze_metrics.py` 离线分析工具，支持灵活调整实验参数（如 `sh_N`, `K`）。

## 2. 实验结果对比

我们进行了多轮实验，从快速验证模式 (`sh_N=1`) 到增强防御模式 (`sh_N=5`, `K=10`)，结果如下：

| 任务类型 | 关键指标 | 本地复现 (DeepSeek) | 论文预期 (Llama-3) | 结论 |
| :--- | :--- | :--- | :--- | :--- |
| **Prompt Injection**<br>(MuSiQue) | **归因精确率** | **100.00%** | ~95%+ | **完美复现**。TracLLM 能精准识别并清除所有恶意注入指令。 |
| | **防御效果** | **完美防御** (ASR=0%) | 完美防御 | 移除 Top-5 关键片段后，攻击完全失效。 |
| **Knowledge Corruption**<br>(NQ-Poison) | **归因精确率** | **80.00%** | ~85-90% | **基本符合**。Top-5 能召回 5 个毒害段落中的 4 个。 |
| | **防御效果** | **防御失败** (ASR=100%) | ASR < 10% | **存在差距**。即使 Top-10 移除，仍漏掉 1 个关键毒害段落，导致防御失效。 |
| **运行效率** | **单条耗时** | **~15 分钟** | ~1-2 分钟 | **受限**。API 网络延迟是主要瓶颈，本地推理会快得多。 |

## 3. 核心洞察

1.  **算法鲁棒性**：
    TracLLM 在 **Prompt Injection** 任务上表现极佳，证明其基于 Shapley 值的归因算法能有效捕捉“指令型”的上下文异常，且对不同模型（Llama vs DeepSeek）具有良好的泛化性。

2.  **防御的木桶效应**：
    在 **Knowledge Corruption** 任务中，防御成功率对归因召回率极度敏感。只要漏掉 1 条毒害信息（Recall < 100%），强大的 LLM（如 DeepSeek）仍能利用残留的毒害信息生成错误答案。这表明单纯依靠 Top-K 移除策略在面对强模型时可能不够，需要更激进的清洗策略。

3.  **计算成本**：
    作为一种基于扰动（Perturbation-based）的方法，TracLLM 需要对模型进行成百上千次推理。在 API 模式下，时间成本较高（单条数据需 10-15 分钟），更适合作为离线分析工具而非实时防御手段。

## 4. 总结

本次复现成功跑通了 TracLLM 的全流程，证实了其作为长文本归因工具的有效性。它能像“手术刀”一样精准剔除恶意指令，但在处理隐蔽性更强的知识投毒时，仍需配合更高的采样率或辅助验证机制来确保 100% 的防御效果。
